# 物理内存

- 操作系统将内存按照page frame方式进行管理，每一个page frame 4KB，那么对于4GB内存而言，一共有4GB/4KB=1M 个page frame

- 内核页面分配和回收API **在内核中逻辑地址（线性映射），虚拟地址()**

| 函数                              | 描述                                                 |
| --------------------------------- | ---------------------------------------------------- |
| alloc_page(gfp_mask)              | 分配一个页面，返回struct page对应的地址              |
| alloc_pages(gfp_mask, order)      | 分配2^order个页面，返回第一个struct page对应的地址   |
| __get_free_page(gfp_mask)         | 分配一个页面，返回页框对应的逻辑地址                 |
| __get_free_pages(gfp_mask, order) | 分配2^order个页面，返回第一个页框对应的逻辑地址      |
| ...                               |                                                      |
| __free_pages(page, order)         | 释放2^order个页面，第一个参数为struct page对应的地址 |
| free_pages(addr, order)           | 释放2^order个页面，第一个参数为页框对应的逻辑地址    |



**记得mem_map这个数组吗？**

- 记录了所有RAM的地址，数组下标表示：page-mem_map，**具体的值<<PAGESHIFT**就是物理地址。

**mem_map**在**init_maps()**中初始化为拥有的内存page数

``` cpp
total_pages = phys_pages + iomem_pages + highmem_pages;
total_len   = phys_len + iomem_len + highmem_len;
map = alloc_bootmem_low_pages(total_len)
```

# vmalloc

该函数的作用是在vmalloc区域找到一个地址addr，用该地址做线性地址完成高端内存页框的映射

- 调用kmalloc分配一个struct vm_struct结构体（内核数据结构，分配在slab上）
- 在vmalloc找寻一个适当的区域赋值给vm_struct的addr字段
- 为addr字段做页表映射，假设分配了3个page（**注意哈，page是通过alloc_page分配来的，具体管理是由伙伴算法进行管理，伙伴算法价格mem_map中空闲的page进行管理**），那么如何制作页表项的呢？
  - 首先将page转换为对应的pfn（页表号） **page-mem_map相减即得page在mem_map中的索引号**
  - 利用上述的索引号<<PAGE_SHIFT，即得物理地址，牛批！
- #返回addr，也就是线性地址

# kmalloc

该函数适用于slab分配内存用的，slab：一种建立在伙伴系统之上的高效内存管理

- 根据源代码来说，slab的内存要么是内核线性区的地址，要么是高端内存（只能是永久映射：**允许内核建立高端页框到内核地址空间的长期映射**），因为在kmem_getpages函数中返回的page是直接通过page_address函数得到虚拟地址的，**然而，该函数的作用是要么直接将page转换为对应的物理地址+PAGE_OFFSET，要么在page_address_htable散列表中查找（该散列表记录的是永久内核映射的page）**

# 伙伴系统

一种解决外碎片的方法，linux内核把左右空闲页框分组为11个链表，每个块链表分别包含大小为1，2，4，8，16，32，...1024个连续的页框。

- 分配算法
  - 假设请求一个256个页框的块（即1MB），算法现在256个页框对应的链表中检查是否有一个空闲块。如果没有这样的块，算法会查找一个更大的链表，也就是在512中查找。如果存在这样的块，内核就把这样的块分成两份，一份插入到256块，一份返回
  - 如果在512中还没有找到合适的，就继续查找更大的块——1024个页框的块，如果这样的页框存在，内核就把1024个页框的块的256个页框用作请求，然后从剩余的768个页框中拿出512个插入到512个页框的链表中，再把最后的256个插入到对应页框的链表中

**分配过程中是不会存在非2次幂page的，这里可以有操作系统保证。需要注意的是：如果内核需要的内存大于4MB怎么办？这时只能连续多次申请4MB内存拼成大块内存，而且检查并保证物理地址连续（为什么只能分配4MB，因为只有11个链表）**

# slab

在伙伴系统之上管理小块内存的分配

- 内核函数倾向于反复请求同一类型的内存区（例如，只要内核创建一个新进程，它就要为一些固定大小的表（如进程描述符，打开文件对象等等）分配内存区）。因为进程的创建和撤销十分频繁，在没有slab分配器时，内核把时间浪费在反复分配和回收那些包含同一内存区的页框上；slab分配器把那些页框保存在高速缓存中并很快的重新使用它们
- 对内存区的请求可以根据它们发生的频率来分类。对于预期频繁请求一个特定大小的内存区而言，可以通过创建一组具有适当大小的专用对象来高效的处理，由此可以避免内碎片的产生。另一种情况，对于很少遇到的内存区大小，可以通过基于一系列几何分布大小的对象的分配模式来处理，即使这种方法会导致内碎片的产生

**slab分为普通高速缓存和专用高速缓存**

- 普通高速缓存是：
  - 第一个高速缓存叫做kmem_cache，包含由内核使用的其余高速缓存的高速缓存描述符。
  - 由13个几何分布的内存区。（32，64，128，256....，131702Bytes）
- 专用高速缓存就是故名思意的

**slab着色**

- 相同大小的对象倾向于存放在高速缓存内相同的偏移量处
- 在不同的slab内具有相同偏移量的对象最终很可能映射在同一高速缓存行中

由于两个对象在同一高速缓存行中，所以可能需要花费更多的内存周期在同一高速缓存行与RAM单元之间来传送两个对象。**slab通过着色来解决这一问题，着色的核心思想：通过空闲内存将slab对象前后移动，相当于改变其偏移量**



